

@article{wang2024mllm,
  title     = {From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs},
  author    = {Wang, Qiru and Laramee, Robert S.},
  journal   = {arXiv preprint},
  year      = {2024},
  eprint    = {2401.15071},
  archivePrefix = {arXiv},
  abstract  = {This paper provides a comparative overview of the latest multimodal large language models (MLLMs), including GPT-4V, Gemini, Claude, and others. The authors evaluate these models across a variety of benchmarks involving image captioning, visual question answering, and instruction following. The study identifies notable differences in multimodal reasoning capabilities, response reliability, and visual grounding among models. In addition, it discusses evaluation challenges such as prompt sensitivity, hallucination, and reproducibility. The paper contributes a structured framework for assessing MLLM performance and emphasizes the need for more transparent benchmarks.},
  keywords  = {type:LLM,multimodal LLM, MLLM, GPT-4V, Gemini, vision-language models, benchmarking, evaluation},
series      = {arXiv Preprints}

}

@article{vaals2024broca,
  title     = {Generating Completions for Fragmented Broca’s Aphasic Sentences Using Large Language Models},
  author    = {van Vaals, Sijbren and Bronstring, Iris and Grootjen, Aico and Heyselaar, Evelien},
  journal   = {arXiv preprint},
  year      = {2024},
  eprint    = {2412.17669},
  archivePrefix = {arXiv},
  abstract  = {This paper investigates the use of large language models (LLMs) to reconstruct fragmented utterances typical of individuals with Broca’s aphasia. The authors generate synthetic training data by applying syntactic deletion rules to grammatically complete sentences, simulating aphasic speech. These data are used to fine-tune T5 and FLAN-T5 models. The study evaluates output quality using BLEU scores, semantic similarity metrics, and human fluency ratings. Results suggest that fine-tuned LLMs are capable of producing syntactically and semantically appropriate sentence completions, demonstrating potential for use in communication support tools for people with aphasia.},
  keywords  = {type:LLM, aphasia, Broca’s aphasia, sentence completion, natural language generation, language disorder},
  series   = {arXiv Preprints}
}

@article{simmons2010partnertraining,
  title     = {Communication partner training in aphasia: A systematic review},
  author    = {Simmons-Mackie, Nina and Raymer, Anastasia and Armstrong, Elizabeth and Holland, Audrey and Cherney, Leora},
  journal   = {Archives of Physical Medicine and Rehabilitation},
  volume    = {91},
  number    = {12},
  pages     = {1814--1837},
  year      = {2010},
  doi       = {10.1016/j.apmr.2010.08.026},
  abstract  = {This systematic review examines 31 studies on communication partner training (CPT) for people with aphasia and their conversation partners. The review explores training methods, intervention outcomes, and measures of communicative success. Most studies employed qualitative assessments or observational metrics. Findings consistently show improvements in mutual understanding, turn-taking, and reduction in communication breakdowns. The review emphasizes the importance of social and interactive elements in aphasia therapy, many of which could inform AI-driven support systems aiming to emulate human-like interaction.},
  keywords  = {type:Overview,aphasia, partner training, systematic review, communication, rehabilitation, qualitative research},
 series     = {Rehabilitation Research} 
}

@article{chen2019automatic,
  title     = {Automatic Assessment of Speech Impairment in Cantonese-Speaking People with Aphasia},
  author    = {Chen, Yu and Wang, Mingyu and Lee, Tan},
  journal   = {IEEE Journal of Selected Topics in Signal Processing},
  volume    = {13},
  number    = {2},
  pages     = {284--294},
  year      = {2019},
  doi       = {10.1109/JSTSP.2019.2956371},
  abstract  = {This study introduces a deep learning-based system for automatically assessing speech impairment severity in Cantonese-speaking individuals with aphasia. Using convolutional neural networks trained on acoustic features, the model captures both articulatory and prosodic cues relevant to impaired speech. The system is evaluated using classification accuracy, confusion matrices, and alignment with expert clinician ratings. The research also tackles unique challenges in analyzing tonal variation in Cantonese. Results suggest strong alignment with clinical judgments, indicating the potential for use in automated diagnosis and remote assessment tools.},
  keywords  = {type:Evaluation,aphasia, speech assessment, deep learning, CNN, Cantonese, tonal language, speech analysis},
  series    = {IEEE Signal Processing}
}

@inproceedings{obamuyide2023aac,
  title     = {Refining Text Input for AAC Devices: Analysing Language Model Layers for Optimisation},
  author    = {Obamuyide, Abiola and Aslam, Jahanzaib and Chamberlain, Jon and Mihaylov, Tsvetomila and Poesio, Massimo},
  booktitle = {Proceedings of the Workshop on Accessible Human-Computer Interfaces},
  year      = {2023},
  note      = {Conference Paper},
  abstract  = {This paper investigates how different layers of large language models contribute to predictive text accuracy in AAC (Augmentative and Alternative Communication) systems. By analyzing layer-wise representations from transformer models, the authors identify which layers most effectively support text prediction for users with communication impairments. The study is aimed at improving the responsiveness and personalization of AAC interfaces. Results suggest that intermediate layers contribute significantly to lexical predictions, providing a basis for fine-tuning strategies in low-resource or personalized settings.},
  keywords  = {type:LLM,AAC, LLM, transformer, predictive text, assistive technology, layer analysis, language modeling},
  series    = {AHCI Workshop Series}
}

@article{tsiartas2013wordnaming,
  title     = {Automatic Word Naming Recognition for an Online Aphasia Treatment System},
  author    = {Tsiartas, Andreas and Georgiou, Panayiotis G. and Narayanan, Shrikanth S.},
  journal   = {Computer Speech \& Language},
  volume    = {27},
  number    = {6},
  pages     = {1233--1245},
  year      = {2013},
  doi       = {10.1016/j.csl.2012.10.003},
  abstract  = {This paper presents a word naming recognition system for use in remote aphasia therapy. The system uses automatic speech recognition to determine whether patients correctly pronounce target words, allowing for remote and semi-automated therapy without constant clinician supervision. The model incorporates acoustic modeling tailored to impaired speech and evaluates recognition accuracy across multiple patient sessions. The results show strong alignment with manual annotations, highlighting the system’s potential for supporting long-term, home-based aphasia treatment.},
  keywords  = {type:Evaluation,aphasia, speech recognition, word naming, ASR, online therapy, automatic feedback},
  series    = {Speech Technology}
}


@article{macwhinney2011aphasiabank,
  title     = {AphasiaBank: A Resource for Clinicians},
  author    = {MacWhinney, Brian and Fromm, Davida and Forbes, Margaret and Holland, Audrey},
  journal   = {Seminars in Speech and Language},
  volume    = {32},
  number    = {3},
  pages     = {253--265},
  year      = {2011},
  doi       = {10.1055/s-0032-1320041},
  abstract  = {AphasiaBank is a multimodal corpus designed to support research and clinical work with individuals who have aphasia. It includes annotated videos, audio, and transcripts of structured language tasks and conversation samples. The database also supports CLAN-based analysis tools for syntactic and semantic tagging, providing a unique resource for clinicians and researchers interested in language production, fluency, and rehabilitation outcomes. The paper discusses its design, annotation schema, and potential uses in diagnosis and treatment.},
  keywords  = {type:Evaluation,aphasia, corpus, dataset, CLAN, multimodal data, language samples, clinical resource},
  series    = {Clinical Linguistics}
}

@article{farrar2023aiaphasia,
  title     = {How artificial intelligence (AI) is used in aphasia rehabilitation: A scoping review},
  author    = {Farrar, Angela and Ward, Elizabeth and Theodoros, Deborah and Ciccone, Natalie and Soh, Selina and Kim, Jemma and Cornwell, Petrea and Godecke, Edith},
  journal   = {Aphasiology},
  year      = {2023},
  doi       = {10.1080/02687038.2023.2189513},
  abstract  = {This scoping review examines how artificial intelligence (AI) has been applied to support aphasia rehabilitation. Drawing on 49 peer-reviewed studies published between 2000 and 2022, the review identifies a wide range of AI applications, including automatic speech recognition, natural language processing, machine learning-based diagnosis, and predictive therapy tools. The authors provide a thematic synthesis of these studies, categorizing them by AI technique, therapeutic goal, evaluation method, and system maturity. They observe a recent rise in personalized, adaptive systems and greater use of large annotated datasets such as AphasiaBank. However, significant gaps remain in clinical validation, user involvement, and ethical transparency. The review highlights the need for interdisciplinary collaboration between AI researchers, clinicians, and people with aphasia to ensure that future systems are inclusive, effective, and aligned with rehabilitation goals.},
  keywords  = {type:Overview,aphasia, artificial intelligence, rehabilitation, speech recognition, NLP, machine learning, scoping review, clinical application},
  series    = {Applied Linguistics}
}

@inproceedings{purohit2023chatgpt,
  title     = {ChatGPT in Healthcare: Exploring AI Chatbot for Spontaneous Word Retrieval in Aphasia},
  author    = {Purohit, Aditya Kumar and Upadhyaya, Anant and Holzer, Alexander},
  booktitle = {Companion Proceedings of the 2023 ACM Conference on Computer Supported Cooperative Work and Social Computing (CSCW '23 Companion)},
  year      = {2023},
  doi       = {10.1145/3584931.3606993},
  abstract  = {This paper explores the use of ChatGPT for assisting individuals with aphasia in retrieving lost words during conversation. The study includes a Wizard-of-Oz-style prototype where participants interact with a simulated version of ChatGPT in real-time. Key findings emphasize the importance of timing, social appropriateness, and politeness strategies in word suggestion. The authors reflect on the need for real-time personalization, adaptive pacing, and trust-building in conversational AI tools designed for people with language impairments.},
  keywords  = {type:LLM,ChatGPT, aphasia, conversational AI, word retrieval, CSCW, real-time interaction},
 series     = {CSCW}
}

@article{mao2025designaac,
  title     = {Design Probes for AI-Driven AAC: Addressing Complex Communication Needs in Aphasia},
  author    = {Mao, Lei and Wang, Yifan and Chowdhury, Fahmida and Vines, Jolyon and Sunderland, Sam and Gilbert, Hamish and Kobori, Shun and Frohlich, David M.},
  journal   = {arXiv preprint},
  year      = {2025},
  eprint    = {2504.09435},
  archivePrefix = {arXiv},
  abstract  = {This design study presents a series of AI-driven AAC (Augmentative and Alternative Communication) prototypes created through a participatory design process involving individuals with aphasia and their support networks. The authors introduce three design probes, each focusing on different communication challenges, such as spontaneous idea generation and repair strategies. Feedback from aphasia users and therapists is analyzed to identify requirements for personalization, emotional sensitivity, and co-creation. The study contributes to the growing field of user-centered AAC tools driven by generative AI.},
  keywords  = {type:AAC, aphasia, co-design, participatory design, user-centered AI, communication support},
 series     = {arXiv Preprints}
}